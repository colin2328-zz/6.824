As the paper argued, it is impossible to know that the processor necessarily failed before or necessarily after executing the IO execution. Therefore, the protocol relied on the 'uncertain' interrupt for the IO instruction. An IO request could be divided into 'updating' (create, update, delete) and 'nonupdating' (read) operations. A protocol that might work is to similiarly use epochs for IO, so that only one 'updating' IO request is done each epoch. If a failure is detected in the middle of the epoch on the master, the backups disk as well as the processor is promoted. This might be slow, but should work. We might also have to worry about disk failures.